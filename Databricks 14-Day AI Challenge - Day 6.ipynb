{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85dcaecb-0e09-45e0-8d5f-4f353c862742",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "# Design 3-layer architecture"
    }
   },
   "outputs": [],
   "source": [
    "# # Bronze Layer: Raw Ingestion\n",
    "# bronze_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/Volumes/workspace/ecommerce/raw/ecommerce_2019_nov.csv\")\n",
    "# display(bronze_df)\n",
    "# # Silver Layer: Cleaning & Validation\n",
    "# from pyspark.sql.functions import col\n",
    "# silver_df = bronze_df.dropDuplicates().filter(col(\"important_column\").isNotNull())\n",
    "# display(silver_df)\n",
    "# # Gold Layer: Business Aggregates\n",
    "# gold_df = silver_df.groupBy(\"business_key\").agg({\"metric_column\": \"sum\"})\n",
    "# display(gold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbb0c7b2-899f-4108-9800-4cb6b4d2e79c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initialize 3-layer paths for CSV files and Delta tables"
    }
   },
   "outputs": [],
   "source": [
    "# # CSV file folder (new directory)\n",
    "# bronze_path = \"/Volumes/workspace/ecommerce/bronze/events\"\n",
    "# silver_path = \"/Volumes/workspace/ecommerce/silver/events\"\n",
    "# gold_path   = \"/Volumes/workspace/ecommerce/gold/events\"\n",
    "# Delta table folder (new directory)\n",
    "bronze_delta_path = \"dbfs:/Volumes/workspace/ecommerce/bronze/events_delta\"\n",
    "silver_delta_path = \"dbfs:/Volumes/workspace/ecommerce/silver/events_delta\"\n",
    "gold_delta_path   = \"dbfs:/Volumes/workspace/ecommerce/gold/events_delta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d420208a-1ccd-41d0-a623-c3c34d3e0dba",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List volumes under schema \"ecommerce\""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>volume_name</th></tr></thead><tbody><tr><td>ecommerce</td><td>bronze</td></tr><tr><td>ecommerce</td><td>delta</td></tr><tr><td>ecommerce</td><td>ecommerce_data</td></tr><tr><td>ecommerce</td><td>gold</td></tr><tr><td>ecommerce</td><td>silver</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ecommerce",
         "bronze"
        ],
        [
         "ecommerce",
         "delta"
        ],
        [
         "ecommerce",
         "ecommerce_data"
        ],
        [
         "ecommerce",
         "gold"
        ],
        [
         "ecommerce",
         "silver"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "database",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "volume_name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql(\"SHOW VOLUMES IN workspace.ecommerce\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3df956a7-c35c-4e71-9369-08eac0a86031",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Bronze Silver Gold Volumes in Ecommerce Schema (first time creation)"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Volume 'workspace.ecommerce.bronze' already exists. Using existing one.\n⚠️ Volume 'workspace.ecommerce.silver' already exists. Using existing one.\n⚠️ Volume 'workspace.ecommerce.gold' already exists. Using existing one.\n"
     ]
    }
   ],
   "source": [
    "# Initialize catalog, schema, volumes\n",
    "catalog = \"workspace\"\n",
    "schema = \"ecommerce\"\n",
    "volumes = [\"bronze\", \"silver\", \"gold\"]\n",
    "\n",
    "for volume in volumes:\n",
    "    try:\n",
    "        spark.sql(f\"CREATE VOLUME {catalog}.{schema}.{volume}\")  # Create volume\n",
    "        print(f\"✅ Volume '{catalog}.{schema}.{volume}' created successfully.\")  # Print success message\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)  # Handle exceptions\n",
    "        # Check if the error is due to the volume already existing\n",
    "        if \"VOLUME_ALREADY_EXISTS\" in error_msg:\n",
    "            print(f\"⚠️ Volume '{catalog}.{schema}.{volume}' already exists. Using existing one.\")\n",
    "        else:\n",
    "            print(f\"❌ Failed to create volume '{catalog}.{schema}.{volume}':\")\n",
    "            print(error_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03f35ad3-904e-48ae-be85-e3dcd09ab6ef",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Copy Raw Ecommerce Data to Bronze Events Directory"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FileInfo(path='dbfs:/Volumes/workspace/ecommerce/bronze/events/2019-Nov.csv', name='2019-Nov.csv', size=9006762395, modificationTime=1769108629000)]\n"
     ]
    }
   ],
   "source": [
    "raw_path = \"dbfs:/Volumes/workspace/ecommerce/ecommerce_data/2019-Nov.csv\"  # Source: Raw volume (ecommerce_data)\n",
    "bronze_path = \"dbfs:/Volumes/workspace/ecommerce/bronze/events/2019-Nov.csv\"  # Destination: Bronze layer\n",
    "dbutils.fs.mkdirs(\"dbfs:/Volumes/workspace/ecommerce/bronze/events\")  # Ensure bronze/events directory exists\n",
    "dbutils.fs.cp(raw_path, bronze_path)  # Copy raw → bronze\n",
    "print(dbutils.fs.ls(\"dbfs:/Volumes/workspace/ecommerce/bronze/events\"))  # Verify if bronze/events directory contains file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aa649c1-4eec-4046-b4c8-d4c398b082da",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Build Bronze: raw ingestion"
    }
   },
   "outputs": [],
   "source": [
    "# Raw data ingestion from source path \"ecommerce_data\" to Bronze layer as Delta table \n",
    "bronze_delta_df = spark.read.format(\"delta\").option(\"header\", \"true\").load(\"/Volumes/workspace/ecommerce/bronze/events/2019-Nov.csv\")\n",
    "bronze_delta_df.write.format(\"delta\").mode(\"overwrite\").save(bronze_delta_path)  # Write to Bronze Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca28d57c-1be7-4966-86b4-65e951c79d52",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Build Silver: cleaning & validation"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp, regexp_replace  # Import necessary libararies \n",
    "silver_delta_df = spark.read.format(\"delta\").load(bronze_delta_path)  # Read from Bronze layer to Silver layer as Delta table\n",
    "# Transform data - perform type conversion, remove null values, drop duplicates\n",
    "silver_delta_df = (silver_delta_df.withColumn(\"event_time\", to_timestamp(col(\"event_time\"))).withColumn(\"price\", col(\"price\").cast(\"double\"))\n",
    "    .filter(col(\"price\").isNotNull())            # remove bad rows\n",
    "    .dropDuplicates()                            # remove duplicates\n",
    ")\n",
    "silver_delta_df.write.format(\"delta\").mode(\"overwrite\").save(silver_delta_path)  # Write to Silver Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0fbec40-bc65-4890-857e-fbaacf499c6e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Build Gold: business aggregates"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum  # Import necessary libararies \n",
    "gold_delta_df = spark.read.format(\"delta\").load(silver_delta_path)  # Read from Silver layer to Gold layer as Delta table\n",
    "gold_delta_df = gold_delta_df.groupBy(\"brand\").agg(sum(\"price\").alias(\"total_revenue\")).orderBy(col(\"total_revenue\").desc())  # Transform data - group by brand, sum price\n",
    "gold_delta_df.write.format(\"delta\").mode(\"overwrite\").save(gold_delta_path)  # Write to Gold Delta table"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7759811467078678,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks 14-Day AI Challenge - Day 6",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}